import ollama
from config import Config
import json

class OllamaClient:
    def __init__(self):
        self.client = ollama.Client(host=Config.OLLAMA_HOST)
        self.model = Config.OLLAMA_MODEL
        self.conversation_history = {}

    def get_system_prompt(self, role='user', context=None):
        """G√©n√®re le prompt syst√®me bas√© sur le r√¥le de l'utilisateur"""

        base_prompt = """Tu es un assistant intelligent pour un syst√®me de gestion des ventes et produits.
Tu aides les utilisateurs √† :
- Rechercher des produits et obtenir des informations d√©taill√©es
- Analyser les performances de vente
- Comprendre les tendances et statistiques
- Identifier les probl√®mes (stock faible, produits lents, etc.)

Tu dois r√©pondre en fran√ßais de mani√®re claire et concise.
Utilise des emojis pour rendre les r√©ponses plus visuelles.
Formate les donn√©es importantes (prix, quantit√©s) de mani√®re lisible.
"""

        role_prompts = {
            'ADMIN': """
Tu assistes un ADMINISTRATEUR. Tu peux l'aider √† :
- Monitorer l'ensemble du syst√®me (ventes, produits, utilisateurs)
- Analyser les performances des vendeurs
- Identifier les alertes critiques (stock faible, produits sans ventes)
- G√©n√©rer des rapports de synth√®se
- Comprendre les KPIs globaux
- Prendre des d√©cisions strat√©giques bas√©es sur les donn√©es
""",
            'VENDEUR': """
Tu assistes un VENDEUR. Tu peux l'aider √† :
- Trouver des produits pour les clients
- Voir ses performances de vente personnelles
- Identifier les produits populaires √† recommander
- Comprendre les tendances de vente
- Optimiser ses ventes quotidiennes
""",
            'ANALYSTE': """
Tu assistes un ANALYSTE. Tu peux l'aider √† :
- Analyser les donn√©es de vente en profondeur
- Identifier les tendances et patterns
- Comparer les performances entre cat√©gories
- G√©n√©rer des insights et recommandations
- Pr√©voir les tendances futures
- Cr√©er des rapports analytiques
""",
            'INVESTISSEUR': """
Tu assistes un INVESTISSEUR. Tu peux l'aider √† :
- Comprendre la sant√© financi√®re de l'entreprise
- Analyser les revenus et la croissance
- Voir les m√©triques cl√©s de performance
- √âvaluer les tendances du march√©
- Obtenir des r√©sum√©s ex√©cutifs
"""
        }

        prompt = base_prompt + role_prompts.get(role.upper(), role_prompts['VENDEUR'])

        if context:
            prompt += f"\n\nContexte actuel des donn√©es:\n{context}"

        return prompt

    def create_context_from_data(self, data):
        """Cr√©e un contexte textuel √† partir des donn√©es"""
        if not data:
            return ""

        context_parts = []

        if 'products' in data:
            products = data['products']
            if isinstance(products, list) and len(products) > 0:
                context_parts.append(f"üì¶ Produits trouv√©s ({len(products)}):")
                for p in products[:5]:  # Limite √† 5 pour le contexte
                    context_parts.append(f"  - {p.get('title', 'N/A')[:50]}... | Prix: {p.get('price', 0):.2f} MAD | Stock: {p.get('stock', 0)}")

        if 'sales_overview' in data:
            overview = data['sales_overview']
            context_parts.append(f"\nüìä Aper√ßu des ventes:")
            context_parts.append(f"  - Total ventes: {overview.get('total_sales', 0)}")
            context_parts.append(f"  - Chiffre d'affaires: {overview.get('total_revenue', 0):.2f} MAD")
            context_parts.append(f"  - Panier moyen: {overview.get('avg_order_value', 0):.2f} MAD")

        if 'inventory' in data:
            inv = data['inventory']
            context_parts.append(f"\nüì¶ Inventaire:")
            context_parts.append(f"  - Total produits: {inv.get('total_products', 0)}")
            context_parts.append(f"  - Rupture de stock: {inv.get('out_of_stock', 0)}")
            context_parts.append(f"  - Stock faible: {inv.get('low_stock', 0)}")

        if 'categories' in data:
            cats = data['categories']
            if isinstance(cats, list) and len(cats) > 0:
                context_parts.append(f"\nüè∑Ô∏è Top cat√©gories:")
                for c in cats[:3]:
                    context_parts.append(f"  - {c.get('category', 'N/A')}: {c.get('total_revenue', 0):.2f} MAD")

        return '\n'.join(context_parts)

    def chat(self, user_id, message, role='user', data_context=None):
        """Envoie un message et obtient une r√©ponse"""

        # Initialise l'historique pour cet utilisateur si n√©cessaire
        if user_id not in self.conversation_history:
            self.conversation_history[user_id] = []

        # Construit le contexte
        context = self.create_context_from_data(data_context) if data_context else None
        system_prompt = self.get_system_prompt(role, context)

        # Ajoute le message utilisateur √† l'historique
        self.conversation_history[user_id].append({
            'role': 'user',
            'content': message
        })

        # Limite l'historique √† 10 messages pour √©viter les tokens excessifs
        history = self.conversation_history[user_id][-10:]

        # Pr√©pare les messages pour Ollama
        messages = [{'role': 'system', 'content': system_prompt}] + history

        try:
            response = self.client.chat(
                model=self.model,
                messages=messages,
                options={
                    'temperature': 0.7,
                    'top_p': 0.9,
                    'num_predict': 1000
                }
            )

            assistant_message = response['message']['content']

            # Ajoute la r√©ponse √† l'historique
            self.conversation_history[user_id].append({
                'role': 'assistant',
                'content': assistant_message
            })

            return {
                'success': True,
                'message': assistant_message,
                'model': self.model
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'message': f"D√©sol√©, je n'ai pas pu traiter votre demande. Erreur: {str(e)}"
            }

    def clear_history(self, user_id):
        """Efface l'historique de conversation d'un utilisateur"""
        if user_id in self.conversation_history:
            self.conversation_history[user_id] = []
        return {'success': True, 'message': 'Historique effac√©'}

    def get_quick_response(self, prompt, context=None):
        """Obtient une r√©ponse rapide sans historique (pour les analyses)"""
        system_prompt = """Tu es un assistant d'analyse de donn√©es.
R√©ponds de mani√®re concise et structur√©e. Utilise des emojis.
Formate les nombres et pourcentages clairement."""

        if context:
            system_prompt += f"\n\nDonn√©es √† analyser:\n{context}"

        try:
            response = self.client.chat(
                model=self.model,
                messages=[
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': prompt}
                ],
                options={
                    'temperature': 0.5,
                    'num_predict': 500
                }
            )
            return response['message']['content']
        except Exception as e:
            return f"Erreur d'analyse: {str(e)}"

    def check_connection(self):
        """V√©rifie la connexion √† Ollama"""
        try:
            models = self.client.list()
            available_models = [m['name'] for m in models.get('models', [])]
            return {
                'connected': True,
                'models': available_models,
                'current_model': self.model,
                'model_available': any(self.model in m for m in available_models)
            }
        except Exception as e:
            return {
                'connected': False,
                'error': str(e)
            }

# Instance globale
ollama_client = OllamaClient()
