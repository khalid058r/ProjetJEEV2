# Python ML & ETL Service

Service Python pour l'e-commerce avec ETL, recherche s√©mantique, chatbot IA et pr√©dictions ML.

## üöÄ Fonctionnalit√©s

| Module | Description |
|--------|-------------|
| **ETL** | Traitement CSV, validation, classification, import Java |
| **Search** | Recherche s√©mantique avec embeddings et FAISS |
| **Chat** | Chatbot IA avec LLM open source (Ollama/HuggingFace) |
| **ML** | Pr√©dictions de rang, recommandations prix, d√©tection best-sellers |

## üì¶ Installation

### 1. Pr√©requis
- Python 3.10+
- (Optionnel) Ollama pour LLM local

### 2. Installation rapide

```bash
# Cloner/Extraire le projet
cd python-service

# Cr√©er environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Installer PyTorch (choisir une option)
pip install torch --index-url https://download.pytorch.org/whl/cpu     # CPU
# pip install torch --index-url https://download.pytorch.org/whl/cu118 # GPU NVIDIA

# Installer les d√©pendances
pip install -r requirements.txt
```

### 3. (Optionnel) Installer Ollama pour le chatbot IA

```bash
# Linux/Mac
curl -fsSL https://ollama.ai/install.sh | sh

# T√©l√©charger un mod√®le
ollama pull mistral   # Recommand√© (~4GB)
# ollama pull phi     # Plus l√©ger (~2GB)

# D√©marrer Ollama
ollama serve
```

## üèÉ D√©marrage

```bash
# D√©marrer le service
python run.py

# Ou directement avec uvicorn
uvicorn app.main:app --host 0.0.0.0 --port 5000 --reload
```

**URLs:**
- API: http://localhost:5000
- Documentation: http://localhost:5000/docs
- ReDoc: http://localhost:5000/redoc

## üì° Endpoints API

### Health
```
GET  /api/health          # Sant√© compl√®te
GET  /api/ping            # Simple ping
GET  /api/info            # Informations service
```

### ETL
```
POST /api/etl/upload                 # Upload et traite un CSV
POST /api/etl/import-to-java         # Importe vers Java
POST /api/etl/upload-and-import      # Upload + Import en une fois
GET  /api/etl/files                  # Liste fichiers upload√©s
GET  /api/etl/classify-rank/{rank}   # Classifie un rang
GET  /api/etl/classify-price/{price} # Classifie un prix
```

### Search
```
POST /api/search                  # Recherche s√©mantique
GET  /api/search/quick?q=...      # Recherche rapide
POST /api/search/index            # Indexe depuis Java
GET  /api/search/similar/{id}     # Produits similaires
GET  /api/search/status           # Statut de l'index
GET  /api/search/categories       # Cat√©gories index√©es
```

### Chat
```
POST /api/chat                    # Envoyer un message
POST /api/chat/init-llm           # Initialiser le LLM
GET  /api/chat/llm-status         # Statut du LLM
GET  /api/chat/{conversation_id}  # Historique conversation
GET  /api/chat/quick-actions      # Actions rapides
```

### ML
```
POST /api/ml/predict-rank         # Pr√©dire le rang
POST /api/ml/recommend-price      # Recommander un prix
POST /api/ml/find-bestsellers     # Trouver best-sellers potentiels
POST /api/ml/train                # Entra√Æner les mod√®les
POST /api/ml/train-from-java      # Entra√Æner depuis Java
POST /api/ml/analyze-product      # Analyse compl√®te d'un produit
GET  /api/ml/status               # Statut des mod√®les
```

## üîß Configuration

Fichier `.env`:

```env
# API
API_HOST=0.0.0.0
API_PORT=5000

# Java Backend
JAVA_BACKEND_URL=http://localhost:8080

# LLM Ollama
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=mistral

# LLM HuggingFace (fallback)
HF_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0

# ML
ML_N_ESTIMATORS=100
ML_MAX_DEPTH=10
```

## üìö Exemples d'utilisation

### 1. Indexer les produits
```bash
curl -X POST "http://localhost:5000/api/search/index"
```

### 2. Rechercher un produit
```bash
curl -X GET "http://localhost:5000/api/search/quick?q=smartphone&limit=5"
```

### 3. Chatter avec l'assistant
```bash
curl -X POST "http://localhost:5000/api/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "Quels sont les meilleurs produits?"}'
```

### 4. Initialiser le LLM
```bash
curl -X POST "http://localhost:5000/api/chat/init-llm?use_ollama=true&ollama_model=mistral"
```

### 5. Entra√Æner les mod√®les ML
```bash
curl -X POST "http://localhost:5000/api/ml/train-from-java"
```

### 6. Analyser un produit
```bash
curl -X POST "http://localhost:5000/api/ml/analyze-product" \
  -H "Content-Type: application/json" \
  -d '{"id":1,"title":"iPhone 15","price":999,"rating":4.8,"review_count":500,"rank":15,"category":"Electronics"}'
```

### 7. Uploader un CSV
```bash
curl -X POST "http://localhost:5000/api/etl/upload" \
  -F "file=@products.csv"
```

## üèóÔ∏è Structure du projet

```
python-service/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health.py      # Endpoints sant√©
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ etl.py         # Endpoints ETL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py      # Endpoints recherche
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.py        # Endpoints chatbot
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ml.py          # Endpoints ML
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py     # Sch√©mas Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ java_client.py     # Client HTTP Java
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ etl_service.py     # Service ETL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_service.py  # Service recherche
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chatbot_service.py # Service chatbot
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_service.py     # Service LLM
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ml_service.py      # Service ML
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configuration
‚îÇ   ‚îî‚îÄ‚îÄ main.py            # Application FastAPI
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ uploads/           # Fichiers upload√©s
‚îÇ   ‚îú‚îÄ‚îÄ processed/         # Fichiers trait√©s
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Mod√®les ML sauvegard√©s
‚îÇ   ‚îî‚îÄ‚îÄ embeddings/        # Index embeddings
‚îú‚îÄ‚îÄ logs/                  # Logs
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ run.py
‚îî‚îÄ‚îÄ .env
```

## üîå Int√©gration avec le projet

### Backend Java Spring Boot

Le service Python communique avec le backend Java via HTTP:

```java
// ProductController.java - endpoints utilis√©s
GET  /api/products          // Liste produits
GET  /api/products/asin/{asin}
POST /api/products          // Cr√©er produit
PUT  /api/products/{id}     // Modifier produit
GET  /api/categories        // Liste cat√©gories
GET  /api/health           // Health check
```

### Frontend React/Vue

```javascript
// Exemple d'int√©gration frontend
const API_BASE = 'http://localhost:5000/api';

// Recherche
const search = async (query) => {
  const res = await fetch(`${API_BASE}/search/quick?q=${query}`);
  return res.json();
};

// Chat
const chat = async (message, conversationId) => {
  const res = await fetch(`${API_BASE}/chat`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ message, conversation_id: conversationId })
  });
  return res.json();
};
```

## üìä Mod√®les ML

### Pr√©diction de Rang
- **Algorithme**: Random Forest Regressor
- **Features**: price, rating, review_count, stock
- **Output**: rang pr√©dit, confiance, tendance

### Recommandation Prix
- **Algorithme**: Gradient Boosting Regressor
- **Features**: rating, review_count, rank
- **Output**: prix recommand√©, variation, raisonnement

### D√©tection Best-Sellers
- **Algorithme**: Random Forest Classifier
- **Features**: rating, review_count, price
- **Output**: score de potentiel, raisons

## ü§ñ LLM Support√©s

| Provider | Mod√®le | RAM | Description |
|----------|--------|-----|-------------|
| Ollama | mistral | 8GB | Recommand√©, excellent √©quilibre |
| Ollama | phi | 4GB | Rapide, l√©ger |
| Ollama | llama2 | 8GB | Meta, bonne qualit√© |
| HuggingFace | TinyLlama | 3GB | Fallback, tr√®s l√©ger |
| HuggingFace | Mistral-7B | 16GB | Tr√®s puissant |

## üìù Licence

MIT License
