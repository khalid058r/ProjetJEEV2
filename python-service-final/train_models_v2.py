"""
Script d'entra√Ænement complet des mod√®les ML V2
Inclut: Price Predictor, Demand Predictor, Bestseller Classifier, FAISS Index
"""

import os
import sys
import pickle
import numpy as np
import pandas as pd
from datetime import datetime
from pathlib import Path

# Ajouter le chemin du projet
sys.path.insert(0, str(Path(__file__).parent))

# Configuration
MODELS_DIR = Path(__file__).parent / 'data' / 'models'
EMBEDDINGS_DIR = Path(__file__).parent / 'data' / 'embeddings'
DATA_DIR = Path(__file__).parent / 'data' / 'uploads'

# Cr√©er les dossiers
MODELS_DIR.mkdir(parents=True, exist_ok=True)
EMBEDDINGS_DIR.mkdir(parents=True, exist_ok=True)


def load_data():
    """Charge les donn√©es depuis le CSV"""
    print("\nüìÇ Chargement des donn√©es...")
    
    csv_paths = [
        DATA_DIR / 'amazon_dataset.csv',
        Path(__file__).parent / 'amazon_dataset.csv',
        Path('amazon_dataset.csv'),
    ]
    
    df = None
    for path in csv_paths:
        if path.exists():
            df = pd.read_csv(path)
            print(f"‚úÖ Donn√©es charg√©es depuis: {path}")
            print(f"   Shape: {df.shape}")
            print(f"   Colonnes: {list(df.columns)}")
            break
    
    if df is None:
        print("‚ùå Fichier CSV non trouv√©!")
        print(f"   Chemins v√©rifi√©s: {csv_paths}")
        return None
    
    return df


def preprocess_data(df):
    """Pr√©traite les donn√©es pour l'entra√Ænement"""
    print("\nüîß Pr√©traitement des donn√©es...")
    
    df = df.copy()
    
    # Normaliser les noms de colonnes (lowercase)
    column_mapping = {
        'ASIN': 'asin',
        'Category': 'category',
        'Product Link': 'product_link',
        'No of Sellers': 'sellers',
        'Rank': 'rank',
        'Rating': 'rating',
        'Reviews Count': 'reviews',
        'Price': 'price',
        'Product_Name': 'title',
        'Description': 'description',
        'Image_URL': 'image_url'
    }
    df.rename(columns=column_mapping, inplace=True)
    print(f"   Colonnes normalis√©es: {list(df.columns)}")
    
    # Nettoyer les prix
    if 'price' in df.columns:
        df['price'] = pd.to_numeric(
            df['price'].astype(str).str.replace(r'[$,‚Ç¨]', '', regex=True), 
            errors='coerce'
        )
        df['price'] = df['price'].fillna(df['price'].median())
        print(f"   Prix: min={df['price'].min():.2f}, max={df['price'].max():.2f}, mean={df['price'].mean():.2f}")
    
    # Nettoyer les ratings
    if 'rating' in df.columns:
        df['rating'] = pd.to_numeric(df['rating'], errors='coerce')
        df['rating'] = df['rating'].fillna(df['rating'].median())
        df['rating'] = df['rating'].clip(0, 5)
        print(f"   Rating: min={df['rating'].min():.2f}, max={df['rating'].max():.2f}")
    
    # Nettoyer les reviews
    if 'reviews' in df.columns:
        df['reviews'] = pd.to_numeric(
            df['reviews'].astype(str).str.replace(r'[,\s]', '', regex=True), 
            errors='coerce'
        )
        df['reviews'] = df['reviews'].fillna(0).astype(int)
        print(f"   Reviews: min={df['reviews'].min()}, max={df['reviews'].max()}")
    
    # Nettoyer le rank
    if 'rank' in df.columns:
        df['rank'] = pd.to_numeric(
            df['rank'].astype(str).str.replace(r'[,\s#]', '', regex=True), 
            errors='coerce'
        )
        df['rank'] = df['rank'].fillna(df['rank'].median())
        print(f"   Rank: min={df['rank'].min():.0f}, max={df['rank'].max():.0f}")
    
    # Demande bas√©e sur rank (invers√©) et reviews
    if 'reviews' in df.columns and 'rating' in df.columns:
        reviews_series = df['reviews'].fillna(0)
        rating_series = df['rating'].fillna(4)
        df['demand'] = (reviews_series * rating_series / 100 + 1)
        df['demand'] = df['demand'].fillna(1)
    else:
        df['demand'] = 1
    print(f"   Demande: min={df['demand'].min():.1f}, max={df['demand'].max():.1f}")
    
    # Label bestseller bas√© sur le rank (top 20%)
    if 'rank' in df.columns:
        threshold = df['rank'].quantile(0.2)  # Top 20% = meilleurs ranks
        df['is_bestseller'] = (df['rank'] <= threshold).astype(int)
    else:
        threshold = df['demand'].quantile(0.8)
        df['is_bestseller'] = (df['demand'] >= threshold).astype(int)
    print(f"   Bestsellers: {df['is_bestseller'].sum()} / {len(df)}")
    
    # Encoder les cat√©gories
    label_encoders = {}
    if 'category' in df.columns:
        from sklearn.preprocessing import LabelEncoder
        le = LabelEncoder()
        df['category_encoded'] = le.fit_transform(df['category'].fillna('Unknown').astype(str))
        label_encoders['category'] = le
        print(f"   Cat√©gories: {len(le.classes_)} uniques")
    
    print(f"‚úÖ Donn√©es pr√©trait√©es: {len(df)} lignes")
    
    return df, label_encoders


def train_price_model(df):
    """Entra√Æne le mod√®le de pr√©diction de prix"""
    print("\nüí∞ Entra√Ænement du mod√®le de PRIX...")
    
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    
    # Features
    feature_cols = ['rating', 'reviews']
    if 'category_encoded' in df.columns:
        feature_cols.append('category_encoded')
    
    available_cols = [col for col in feature_cols if col in df.columns]
    
    if len(available_cols) < 2 or 'price' not in df.columns:
        print("‚ö†Ô∏è Colonnes insuffisantes pour le mod√®le de prix")
        return None, None, feature_cols
    
    X = df[available_cols].fillna(0)
    y = df['price']
    
    # Supprimer les valeurs aberrantes
    mask = (y > 0) & (y < y.quantile(0.99))
    X = X[mask]
    y = y[mask]
    
    print(f"   Features: {available_cols}")
    print(f"   √âchantillons: {len(X)}")
    
    # Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Scaler
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Mod√®le
    model = RandomForestRegressor(
        n_estimators=100,
        max_depth=10,
        min_samples_split=5,
        random_state=42,
        n_jobs=-1
    )
    
    model.fit(X_train_scaled, y_train)
    
    # √âvaluation
    y_pred = model.predict(X_test_scaled)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    print(f"   ‚úÖ RMSE: {rmse:.2f}")
    print(f"   ‚úÖ MAE: {mae:.2f}")
    print(f"   ‚úÖ R¬≤: {r2:.3f}")
    
    # Cross-validation
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')
    print(f"   ‚úÖ CV R¬≤ mean: {cv_scores.mean():.3f} (+/- {cv_scores.std()*2:.3f})")
    
    return model, scaler, available_cols


def train_demand_model(df):
    """Entra√Æne le mod√®le de pr√©diction de demande"""
    print("\nüì¶ Entra√Ænement du mod√®le de DEMANDE...")
    
    from sklearn.ensemble import GradientBoostingRegressor
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import mean_squared_error, r2_score
    
    feature_cols = ['price', 'rating', 'reviews']
    if 'category_encoded' in df.columns:
        feature_cols.append('category_encoded')
    
    available_cols = [col for col in feature_cols if col in df.columns]
    
    if len(available_cols) < 2 or 'demand' not in df.columns:
        print("‚ö†Ô∏è Colonnes insuffisantes pour le mod√®le de demande")
        return None
    
    X = df[available_cols].fillna(0)
    y = df['demand']
    
    print(f"   Features: {available_cols}")
    print(f"   √âchantillons: {len(X)}")
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = GradientBoostingRegressor(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        random_state=42
    )
    
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    
    print(f"   ‚úÖ RMSE: {rmse:.2f}")
    print(f"   ‚úÖ R¬≤: {r2:.3f}")
    
    return model


def train_bestseller_model(df):
    """Entra√Æne le mod√®le de classification bestseller"""
    print("\nüåü Entra√Ænement du mod√®le BESTSELLER...")
    
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score, f1_score, classification_report
    
    feature_cols = ['price', 'rating', 'reviews']
    if 'category_encoded' in df.columns:
        feature_cols.append('category_encoded')
    
    available_cols = [col for col in feature_cols if col in df.columns]
    
    if len(available_cols) < 2 or 'is_bestseller' not in df.columns:
        print("‚ö†Ô∏è Colonnes insuffisantes pour le mod√®le bestseller")
        return None
    
    X = df[available_cols].fillna(0)
    y = df['is_bestseller']
    
    print(f"   Features: {available_cols}")
    print(f"   √âchantillons: {len(X)}")
    print(f"   Distribution: {dict(y.value_counts())}")
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=5,
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )
    
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    print(f"   ‚úÖ Accuracy: {accuracy:.3f}")
    print(f"   ‚úÖ F1 Score: {f1:.3f}")
    
    return model


def create_faiss_index(df):
    """Cr√©e l'index FAISS pour la recherche s√©mantique"""
    print("\nüîç Cr√©ation de l'index FAISS...")
    
    try:
        import faiss
        from sklearn.feature_extraction.text import TfidfVectorizer
    except ImportError as e:
        print(f"‚ö†Ô∏è D√©pendance manquante: {e}")
        return None, None, None
    
    if 'title' not in df.columns:
        print("‚ö†Ô∏è Colonne 'title' manquante")
        return None, None, None
    
    # Cr√©er les embeddings TF-IDF des titres
    titles = df['title'].fillna('').astype(str).tolist()
    
    if 'asin' in df.columns:
        asins = df['asin'].tolist()
    else:
        asins = list(range(len(df)))
    
    vectorizer = TfidfVectorizer(max_features=256, stop_words='english')
    embeddings = vectorizer.fit_transform(titles).toarray().astype('float32')
    
    print(f"   Embeddings shape: {embeddings.shape}")
    
    # Cr√©er l'index FAISS
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings)
    
    print(f"   ‚úÖ Index cr√©√© avec {index.ntotal} vecteurs")
    
    return index, asins, embeddings


def save_models(price_model, scaler, demand_model, bestseller_model, label_encoders, feature_columns):
    """Sauvegarde tous les mod√®les"""
    print("\nüíæ Sauvegarde des mod√®les...")
    
    if price_model:
        with open(MODELS_DIR / 'price_predictor.pkl', 'wb') as f:
            pickle.dump(price_model, f)
        print("   ‚úÖ price_predictor.pkl")
    
    if scaler:
        with open(MODELS_DIR / 'scaler.pkl', 'wb') as f:
            pickle.dump(scaler, f)
        print("   ‚úÖ scaler.pkl")
    
    if demand_model:
        with open(MODELS_DIR / 'demand_predictor.pkl', 'wb') as f:
            pickle.dump(demand_model, f)
        print("   ‚úÖ demand_predictor.pkl")
    
    if bestseller_model:
        with open(MODELS_DIR / 'bestseller_classifier.pkl', 'wb') as f:
            pickle.dump(bestseller_model, f)
        print("   ‚úÖ bestseller_classifier.pkl")
    
    if label_encoders:
        with open(MODELS_DIR / 'label_encoders.pkl', 'wb') as f:
            pickle.dump(label_encoders, f)
        print("   ‚úÖ label_encoders.pkl")
    
    if feature_columns:
        with open(MODELS_DIR / 'feature_columns.pkl', 'wb') as f:
            pickle.dump(feature_columns, f)
        print("   ‚úÖ feature_columns.pkl")


def save_faiss_index(index, product_ids, embeddings):
    """Sauvegarde l'index FAISS"""
    print("\nüíæ Sauvegarde de l'index FAISS...")
    
    try:
        import faiss
        
        if index:
            faiss.write_index(index, str(EMBEDDINGS_DIR / 'products.index'))
            print("   ‚úÖ products.index")
        
        if product_ids:
            with open(EMBEDDINGS_DIR / 'product_ids.pkl', 'wb') as f:
                pickle.dump(product_ids, f)
            print("   ‚úÖ product_ids.pkl")
        
        if embeddings is not None:
            np.save(EMBEDDINGS_DIR / 'product_embeddings.npy', embeddings)
            print("   ‚úÖ product_embeddings.npy")
            
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur sauvegarde FAISS: {e}")


def main():
    """Point d'entr√©e principal"""
    print("=" * 60)
    print("üöÄ ENTRA√éNEMENT DES MOD√àLES ML V2")
    print(f"   Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # 1. Charger les donn√©es
    df = load_data()
    if df is None:
        return
    
    # 2. Pr√©traiter
    df, label_encoders = preprocess_data(df)
    
    # 3. Entra√Æner les mod√®les
    price_model, scaler, feature_columns = train_price_model(df)
    demand_model = train_demand_model(df)
    bestseller_model = train_bestseller_model(df)
    
    # 4. Cr√©er l'index FAISS
    faiss_index, product_ids, embeddings = create_faiss_index(df)
    
    # 5. Sauvegarder
    save_models(price_model, scaler, demand_model, bestseller_model, label_encoders, feature_columns)
    save_faiss_index(faiss_index, product_ids, embeddings)
    
    print("\n" + "=" * 60)
    print("‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS!")
    print("=" * 60)
    
    # R√©sum√©
    print("\nüìä R√âSUM√â:")
    print(f"   Mod√®les sauvegard√©s dans: {MODELS_DIR}")
    print(f"   Index FAISS dans: {EMBEDDINGS_DIR}")
    print(f"   Nombre de produits: {len(df)}")
    
    models_status = {
        "price_model": price_model is not None,
        "demand_model": demand_model is not None,
        "bestseller_model": bestseller_model is not None,
        "faiss_index": faiss_index is not None
    }
    
    for model, status in models_status.items():
        icon = "‚úÖ" if status else "‚ùå"
        print(f"   {icon} {model}")


if __name__ == "__main__":
    main()
