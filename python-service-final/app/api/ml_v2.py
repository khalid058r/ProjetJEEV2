"""
API Routes - Machine Learning V2
Utilise les mod√®les ML entra√Æn√©s (.pkl) pour les pr√©dictions
"""
from fastapi import APIRouter, HTTPException, Query
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
import logging

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/ml/v2", tags=["ML V2 - Mod√®les Entra√Æn√©s"])


# ============================================================================
# SCH√âMAS DE REQU√äTE/R√âPONSE
# ============================================================================

class ProductInput(BaseModel):
    """Donn√©es produit pour les pr√©dictions (compatible avec Java ProductInputDTO)"""
    id: Optional[str] = None
    name: Optional[str] = None  # Java envoie 'name'
    title: Optional[str] = None  # Pour compatibilit√©
    price: float = Field(default=0, ge=0)
    rating: float = Field(default=0, ge=0, le=5)
    reviews: int = Field(default=0, ge=0)  # Pour compatibilit√©
    reviewCount: int = Field(default=0, ge=0)  # Java envoie 'reviewCount'
    category: Optional[str] = None
    description: Optional[str] = None
    stock: int = Field(default=0, ge=0)
    rank: int = Field(default=0, ge=0)
    
    @property
    def product_name(self) -> str:
        """Retourne le nom du produit (name ou title)"""
        return self.name or self.title or "Unknown"
    
    @property
    def review_count(self) -> int:
        """Retourne le nombre de reviews (reviewCount ou reviews)"""
        return self.reviewCount or self.reviews or 0


class PricePredictionResponse(BaseModel):
    """R√©ponse pr√©diction de prix"""
    success: bool = True
    predicted_price: float = Field(alias="predictedPrice", default=0)
    confidence: float = 0.85
    confidence_interval: Optional[Dict[str, float]] = Field(alias="confidenceInterval", default=None)
    price_range: Optional[Dict[str, float]] = Field(alias="priceRange", default=None)
    model_used: str = Field(alias="modelUsed", default="RandomForest")
    features_used: List[str] = Field(alias="featuresUsed", default=[])
    recommendation: Optional[str] = None
    error: Optional[str] = None

    class Config:
        populate_by_name = True


class DemandPredictionResponse(BaseModel):
    """R√©ponse pr√©diction de demande"""
    success: bool = True
    predicted_demand: float = Field(alias="predictedDemand", default=0)
    predicted_demand_total: Optional[float] = None
    predicted_demand_daily_avg: Optional[float] = None
    daily_forecast: List[Dict[str, Any]] = Field(alias="dailyForecast", default=[])
    trend: str = "stable"
    confidence: float = 0.80
    current_stock: Optional[int] = None
    days_of_stock: Optional[float] = None
    urgency: Optional[str] = None
    recommendation: Optional[str] = None
    model_used: str = Field(alias="modelUsed", default="GradientBoosting")
    error: Optional[str] = None

    class Config:
        populate_by_name = True


class BestsellerPredictionResponse(BaseModel):
    """R√©ponse pr√©diction bestseller"""
    success: bool = True
    is_bestseller: bool = Field(alias="isBestseller", default=False)
    probability: float = 0.5
    bestseller_probability: Optional[float] = Field(alias="bestsellerProbability", default=None)
    confidence: str = "medium"
    factors: List[str] = []
    recommendation: Optional[str] = None
    model_used: str = Field(alias="modelUsed", default="RandomForest")
    error: Optional[str] = None

    class Config:
        populate_by_name = True


class SemanticSearchResult(BaseModel):
    """R√©sultat de recherche s√©mantique"""
    product_id: str
    score: float
    title: Optional[str] = None


class SemanticSearchResponse(BaseModel):
    """R√©ponse recherche s√©mantique"""
    query: str
    results: List[SemanticSearchResult]
    total_found: int
    index_used: str


class SimilarProductResponse(BaseModel):
    """Produit similaire"""
    product_id: str
    similarity_score: float
    title: Optional[str] = None


class ProductAnalysisResponse(BaseModel):
    """Analyse compl√®te d'un produit"""
    product_id: Optional[str]
    price_prediction: Optional[Dict[str, Any]]
    demand_prediction: Optional[Dict[str, Any]]
    bestseller_prediction: Optional[Dict[str, Any]]
    similar_products: Optional[List[Dict[str, Any]]]


# ============================================================================
# INITIALISATION DU SERVICE
# ============================================================================

def get_ml_service():
    """R√©cup√®re ou initialise le service ML V2"""
    from app.services.ml_service_v2 import MLServiceV2
    return MLServiceV2()


# ============================================================================
# ENDPOINTS - PR√âDICTIONS
# ============================================================================

@router.post("/predict/price", response_model=PricePredictionResponse)
async def predict_price(product: ProductInput):
    """
    üéØ Pr√©dit le prix optimal d'un produit
    
    Utilise un mod√®le RandomForest entra√Æn√© sur les donn√©es historiques.
    Retourne une pr√©diction avec intervalle de confiance.
    """
    try:
        ml_service = get_ml_service()
        result = ml_service.predict_price(product.model_dump())
        return result
    except Exception as e:
        logger.error(f"‚ùå Erreur pr√©diction prix: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/predict/demand", response_model=DemandPredictionResponse)
async def predict_demand(
    product: ProductInput,
    days: int = Query(default=30, ge=1, le=365, description="Nombre de jours √† pr√©voir")
):
    """
    üì¶ Pr√©dit la demande future d'un produit
    
    Utilise un mod√®le GradientBoosting pour pr√©dire les ventes.
    Retourne une pr√©vision quotidienne avec tendance.
    """
    try:
        ml_service = get_ml_service()
        result = ml_service.predict_demand(product.model_dump(), days=days)
        return result
    except Exception as e:
        logger.error(f"‚ùå Erreur pr√©diction demande: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/predict/bestseller", response_model=BestsellerPredictionResponse)
async def predict_bestseller(product: ProductInput):
    """
    üåü Pr√©dit si un produit sera un bestseller
    
    Utilise un classificateur RandomForest pour d√©terminer
    le potentiel bestseller avec probabilit√©.
    """
    try:
        ml_service = get_ml_service()
        result = ml_service.predict_bestseller(product.model_dump())
        return result
    except Exception as e:
        logger.error(f"‚ùå Erreur pr√©diction bestseller: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# ENDPOINTS - RECHERCHE S√âMANTIQUE
# ============================================================================

@router.get("/search", response_model=SemanticSearchResponse)
async def semantic_search(
    query: str = Query(..., min_length=2, description="Requ√™te de recherche"),
    top_k: int = Query(default=10, ge=1, le=100, description="Nombre de r√©sultats")
):
    """
    üîç Recherche s√©mantique de produits
    
    Utilise FAISS et les embeddings TF-IDF pour trouver
    les produits les plus pertinents.
    """
    try:
        ml_service = get_ml_service()
        result = ml_service.semantic_search(query, top_k=top_k)
        return result
    except Exception as e:
        logger.error(f"‚ùå Erreur recherche: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/similar/{product_id}")
async def find_similar_products(
    product_id: str,
    top_k: int = Query(default=5, ge=1, le=20, description="Nombre de produits similaires")
):
    """
    üîó Trouve les produits similaires
    
    Utilise la similarit√© vectorielle pour trouver
    les produits les plus proches.
    """
    try:
        ml_service = get_ml_service()
        result = ml_service.find_similar_products(product_id, top_k=top_k)
        return result
    except Exception as e:
        logger.error(f"‚ùå Erreur produits similaires: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# ENDPOINTS - ANALYSE COMPL√àTE
# ============================================================================

@router.post("/analyze", response_model=ProductAnalysisResponse)
async def analyze_product(product: ProductInput):
    """
    üìä Analyse compl√®te d'un produit
    
    Combine toutes les pr√©dictions:
    - Prix optimal
    - Demande pr√©vue
    - Potentiel bestseller
    - Produits similaires
    """
    try:
        ml_service = get_ml_service()
        result = ml_service.analyze_product(product.model_dump())
        return result
    except Exception as e:
        logger.error(f"‚ùå Erreur analyse: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/batch-analyze")
async def batch_analyze(
    products: List[ProductInput],
    limit: int = Query(default=50, ge=1, le=100)
):
    """
    üìä Analyse en lot de plusieurs produits
    """
    try:
        ml_service = get_ml_service()
        results = []
        
        for product in products[:limit]:
            try:
                analysis = ml_service.analyze_product(product.model_dump())
                results.append(analysis)
            except Exception as e:
                logger.warning(f"Erreur analyse produit: {e}")
                continue
        
        return {
            "total_requested": len(products),
            "total_analyzed": len(results),
            "results": results
        }
    except Exception as e:
        logger.error(f"‚ùå Erreur batch: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# ENDPOINTS - GESTION DES MOD√àLES
# ============================================================================

@router.get("/models/status")
async def get_models_status():
    """
    ‚ÑπÔ∏è Statut des mod√®les ML charg√©s
    
    Retourne l'√©tat de chaque mod√®le et de l'index FAISS.
    """
    try:
        ml_service = get_ml_service()
        return ml_service.get_status()
    except Exception as e:
        logger.error(f"‚ùå Erreur statut: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/models/reload")
async def reload_models():
    """
    üîÑ Recharge les mod√®les depuis le disque
    
    Utile apr√®s un nouvel entra√Ænement.
    """
    try:
        ml_service = get_ml_service()
        ml_service._load_models()
        ml_service._load_faiss_index()
        
        return {
            "success": True,
            "message": "Mod√®les recharg√©s",
            "status": ml_service.get_status()
        }
    except Exception as e:
        logger.error(f"‚ùå Erreur reload: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/train")
async def train_models(products: List[dict]):
    """
    üéì Entra√Æne les mod√®les avec de nouvelles donn√©es
    
    N√©cessite au moins 50 produits.
    """
    if len(products) < 50:
        raise HTTPException(
            status_code=400,
            detail=f"Minimum 50 produits requis ({len(products)} fournis)"
        )
    
    try:
        # Import et ex√©cution du training
        import subprocess
        import sys
        from pathlib import Path
        
        train_script = Path(__file__).parent.parent.parent / 'train_models_v2.py'
        
        if not train_script.exists():
            raise HTTPException(
                status_code=500,
                detail="Script d'entra√Ænement non trouv√©"
            )
        
        # Ex√©cuter l'entra√Ænement
        result = subprocess.run(
            [sys.executable, str(train_script)],
            capture_output=True,
            text=True,
            timeout=300
        )
        
        if result.returncode != 0:
            raise HTTPException(
                status_code=500,
                detail=f"Erreur entra√Ænement: {result.stderr}"
            )
        
        # Recharger les mod√®les
        ml_service = get_ml_service()
        ml_service._load_models()
        ml_service._load_faiss_index()
        
        return {
            "success": True,
            "message": "Mod√®les entra√Æn√©s et recharg√©s",
            "output": result.stdout[-500:] if result.stdout else "",
            "status": ml_service.get_status()
        }
        
    except subprocess.TimeoutExpired:
        raise HTTPException(status_code=500, detail="Timeout entra√Ænement")
    except Exception as e:
        logger.error(f"‚ùå Erreur train: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/health")
async def ml_health_check():
    """üè• V√©rification de sant√© du service ML"""
    try:
        ml_service = get_ml_service()
        status = ml_service.get_status()
        
        models_loaded = sum([
            status.get('price_model_loaded', False),
            status.get('demand_model_loaded', False),
            status.get('bestseller_model_loaded', False)
        ])
        
        return {
            "status": "healthy" if models_loaded >= 2 else "degraded" if models_loaded >= 1 else "unhealthy",
            "models_loaded": models_loaded,
            "faiss_ready": status.get('faiss_ready', False),
            "details": status
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e)
        }
