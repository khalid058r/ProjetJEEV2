# ============================================
# PYTHON ML & ETL SERVICE - REQUIREMENTS
# ============================================

# === Web Framework ===
fastapi==0.109.0
uvicorn[standard]==0.27.0
pydantic==2.9.2
pydantic-settings==2.6.1
python-multipart==0.0.6
flask==3.0.0
flask-cors==4.0.0

# === Data Processing ===
pandas==2.1.4
numpy==1.26.4
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
requests==2.31.0

# === Machine Learning ===
scikit-learn==1.4.0
joblib==1.3.2

# === NLP & Embeddings ===
sentence-transformers==2.3.1
transformers==4.36.2

# === Vector Search ===
faiss-cpu==1.7.4

# === LLM HuggingFace (optionnel mais recommandé) ===
accelerate==0.25.0
# PyTorch - installer séparément:
# CPU: pip install torch --index-url https://download.pytorch.org/whl/cpu
# GPU: pip install torch --index-url https://download.pytorch.org/whl/cu118

# === HTTP Client ===
httpx==0.26.0
aiohttp==3.9.1

# === Utilities ===
python-dotenv==1.0.0
tenacity==8.2.3
chardet==5.2.0

# === Testing ===
pytest==7.4.4
pytest-asyncio==0.23.3

# === LLM APIs ===
groq==0.4.1
openai==1.6.1

# ============================================
# INSTALLATION
# ============================================
# 
# 1. Créer environnement virtuel:
#    python -m venv venv
#    source venv/bin/activate  (Linux/Mac)
#    venv\Scripts\activate     (Windows)
#
# 2. Installer PyTorch (choisir une option):
#    CPU: pip install torch --index-url https://download.pytorch.org/whl/cpu
#    GPU: pip install torch --index-url https://download.pytorch.org/whl/cu118
#
# 3. Installer les dépendances:
#    pip install -r requirements.txt
#
# 4. (Optionnel) Installer Ollama pour LLM local:
#    https://ollama.ai
#    ollama pull mistral
#
# ============================================
